# EntityAlignment

##  Environment Setup

To reproduce the development environment and run the application, follow these steps:

### 1. Install Conda

If you don’t already have Conda installed, you can install [Miniconda](https://docs.conda.io/en/latest/miniconda.html):

```bash
# On Linux or macOS
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh
```
### 2. Create the Conda Environment
```bash
conda env create -f environment.yml
```

### 3. Activate the Environment
```bash
conda activate entity-alignment
```

### 3. Setup dependencies

The application requires OpenAI API key for classification with LLM
The key should be placed in a file [.env](.env)
With content:

OPENAI_API_KEY="your key"


The application requires a running GraphDB instance
The provided [docker-compose.yml](docker-compose/docker-compose.yml) can be used to start GraphDB

Docker and docker-compose are required to be installed.
The docker-compose can be started with (executed from the root project folder):
```bash
/usr/bin/docker-compose -f docker-compose/docker-compose.yml -p docker-compose up -d
```

If execution is successfull the GraphDB workbench should be available at http://localhost:7200/

This setup also persists the ingested data into folder docker-compose/data

Alternatively GraphDB can be started as an executable, more info at https://graphdb.ontotext.com/documentation/10.8/graphdb-desktop-installation.html

The data used for the project can be provided on request. (If not already present)

It contains rdf files of ontologies from https://bioportal.bioontology.org/ontologies
And additionally it has two Similarity indexes created "doid_labels" and "mesh_labels", created respectively from the DOID and MESH ontologies.

### 5. Run the App
```bash
streamlit run app/demo.py
```

##  Data Setup

The data used in the tasks has the following structure - data folder under the root project directory:

data/
├── candidates/              
├── datasets/
│   └── csv/                 
├── mappings/                
├── similarity_config.json

candidates/ – Stores intermediate or final candidate pairs generated by the alignment algorithm  (e.g., top-k entity candidates). 
Similarity Search Evaluation in the application

datasets/csv/ - contains the available datasets in csv format. For biomedical datasets can be downloaded from - https://bioportal.bioontology.org/ontologies

mappings/ - contains the available mappings for the datasets. For biomedical mappings can be downloaded from https://bioportal.bioontology.org/mappings
The files should be with name with names <*_mappings_GraphA_GraphB>.csv. and should contain two columns. 

similarity_config.json - represent a configuration for the available mappings files for each graph pair

Example similarity_config.json
```
{
  "ICD10CM-DOID": [
    "mappings_doid_icd10cm.csv",
    "extended_mappings_doid_icd10cm.csv"
  ],
  "MESH-DOID" : [
    "mappings_doid_mesh.csv"
  ],
  "DOID-MESH" : [
    "mappings_doid_mesh.csv"
  ]
}
```
